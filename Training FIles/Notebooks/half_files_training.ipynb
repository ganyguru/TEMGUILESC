{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as nd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "#session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]= \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "except:\n",
    "    print('whss')\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_virtual_device_configuration(\n",
    "#   physical_devices[0],\n",
    "#   [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000),\n",
    "#   tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "#     try:\n",
    "#         tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "#         logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#     except RuntimeError as e:\n",
    "#     # Visible devices must be set before GPUs have been initialized\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9ocdOhZgiKf",
    "outputId": "96cd12de-d915-4069-ffe9-5a14fe1013a5"
   },
   "outputs": [],
   "source": [
    "\n",
    "    seed = 42\n",
    "    np.random.seed = seed\n",
    "\n",
    "\n",
    "    IMG_WIDTH = 512\n",
    "    IMG_HEIGHT = 1024\n",
    "    IMG_CHANNELS = 3\n",
    "\n",
    "    TRAIN_PATH = '../data_files/files_half/traindata/'\n",
    "    TRAIN_PATH_Y = '../data_files/files_half/groundtruth/'\n",
    "    TEST_PATH = '../data_files/files_half/testdata/'\n",
    "    TEST_PATH_Y = '../data_files/files_half/testy/'\n",
    "\n",
    "    train_files=[]\n",
    "    for file in os.listdir(\"../data_files/files_half/traindata\"):\n",
    "        if file.endswith(\".png\"):\n",
    "            train_files.append(file)\n",
    "\n",
    "    \n",
    "    train_files_y=[]\n",
    "    for file in os.listdir(\"../data_files/files_half/groundtruth\"):\n",
    "        if file.endswith(\".png\"):\n",
    "            train_files_y.append(file)\n",
    "\n",
    "#test_files=[]\n",
    "#for file in os.listdir(\"/content/files3_512/testdata\"):\n",
    "#    if file.endswith(\".png\"):\n",
    "#        test_files.append(file)\n",
    "\n",
    "    X_train = np.zeros((len(train_files),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS), dtype = np.uint8)\n",
    "    Y_train = np.zeros((len(train_files),IMG_HEIGHT,IMG_WIDTH,1), dtype = np.bool)\n",
    "\n",
    "#train_files.sort()\n",
    "#train_files_y.sort()\n",
    "    i=0\n",
    "    for file in train_files:\n",
    "        path = TRAIN_PATH + file\n",
    "        img = cv2.imread(path)[:,:,:IMG_CHANNELS]  \n",
    "    \n",
    "        #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        #img = np.expand_dims(img,axis=2)\n",
    "        X_train[i]=img\n",
    "        path=''\n",
    "        path = TRAIN_PATH_Y + file\n",
    "        img = cv2.imread(path)[:,:,:1]  \n",
    "    #img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "        #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #img = np.expand_dims(img,axis=2)\n",
    "        Y_train[i]=img\n",
    "        i=i+1\n",
    "\n",
    "    i=0\n",
    "\n",
    "#X_test = np.zeros((len(test_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "#sizes_test = []\n",
    "#for file in test_files:\n",
    "#    path = TEST_PATH + file\n",
    "#    img = cv2.imread(path)[:,:,:IMG_CHANNELS]\n",
    "#    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    #img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "    #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #img = np.expand_dims(img,axis=2)\n",
    "#    X_test[i] = img\n",
    "#    i=i+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHQHLYT2VmB7"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT,IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFgu9TPkmzRX"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Contraction path\n",
    "\n",
    "nfilters=1024\n",
    "\n",
    "c1 = tf.keras.layers.Conv2D(int(nfilters/8), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(int(nfilters/8), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(int(nfilters/4), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(int(nfilters/4), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(int(nfilters/2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(int(nfilters/2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(int(nfilters), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(int(nfilters), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(int(nfilters*2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(int(nfilters*2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "\n",
    "#Expansive path \n",
    "u6 = tf.keras.layers.Conv2DTranspose(int(nfilters), (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(int(nfilters), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(int(nfilters), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(int(nfilters/2), (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(int(nfilters/2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(int(nfilters/2), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(int(nfilters/4), (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(int(nfilters/4), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(int(nfilters/4), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(int(nfilters/8), (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(int(nfilters/8), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(int(nfilters/8), (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv1GG1VsFCut"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return numerator / (denominator + tf.keras.backend.epsilon()) \n",
    "\n",
    "model2 = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])\n",
    "model2.optimizer.lr=0.0001\n",
    "\n",
    "\n",
    "#model.save('trained_model.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('/home/meng/Gany_Lab/TEM_processing/MRCFILE/model_1024_prec_6.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqIX8XSOrDdt",
    "outputId": "e6a612ed-8004-4f9f-98a9-c62937e2a8b7"
   },
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('unet_membrane.hdf5',verbose = 1, save_best_only=True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 10,monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "results = model2.fit(X_train,Y_train,validation_split=0.1,batch_size=4,epochs=100,callbacks=callbacks)\n",
    "#model2.save('channel_1_1024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OQxaKzx5OiL"
   },
   "outputs": [],
   "source": [
    " model2.save_weights('channel_1_1024.hdf5',save_format='hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SL_paBf6tJts"
   },
   "outputs": [],
   "source": [
    "model2.save('channel_1_1024',save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ojv66pdGzUr2",
    "outputId": "5a0d6f3d-4350-4a78-8538-ebc370b1e845"
   },
   "outputs": [],
   "source": [
    "!zip -r model_contour.zip contour_model_256/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_LMGmGzrWx4"
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    return 1\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return numerator / (denominator + tf.keras.backend.epsilon()) \n",
    "\n",
    "contour_model = tf.keras.models.load_model('contour_model_256', custom_objects = {\"f1\": f1, \"dice_coefficient\": dice_coefficient})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BvO0g7rxyQ2",
    "outputId": "167ed335-b433-446a-9609-2932333a58fa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ew08Chvzx66z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68zhngqKz68b"
   },
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('contour_model_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNNubKYgGhux"
   },
   "outputs": [],
   "source": [
    "model=model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWIusnn1zhDZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "score, acc = model.evaluate(xt,yt\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p32FCtWL1W7K"
   },
   "outputs": [],
   "source": [
    "!mkdir testimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlB6XEgg1b_Q"
   },
   "outputs": [],
   "source": [
    "!mkdir predimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "kxstWLXh1jzX",
    "outputId": "26eafe07-93f3-4e58-f5c3-9225454fceb0"
   },
   "outputs": [],
   "source": [
    "preds_test = model2.predict(xt, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1NGOtqf1sVe"
   },
   "outputs": [],
   "source": [
    "preds_test_t= (preds_test > 0.1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cn_Xwq9t3XyO"
   },
   "outputs": [],
   "source": [
    "ytt = (yt).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "ZbZ-tyap3DTf",
    "outputId": "15697cb3-84d9-416b-c3f9-f9118651cc14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jscores = []\n",
    "for i in range(0,200):\n",
    " jscores.append(jaccard_score(np.squeeze(ytt[i]).reshape(-1), np.squeeze(preds_test_t[i]).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vELlSwx3Pko",
    "outputId": "ec613edb-b1ac-4906-9599-7f20c4015a4c"
   },
   "outputs": [],
   "source": [
    "np.mean(jscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWpP-n6Km7wX",
    "outputId": "d6bb55fe-caf2-4209-fb81-33f8a8889cd1"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds_test = model2.predict(X_test, verbose=1)\n",
    "\n",
    "preds_test= (preds_test > 0.4).astype(np.uint8)\n",
    "\n",
    "plt.imsave('img1.png',(np.squeeze(preds_test[0])),cmap='gray')\n",
    "plt.imsave('img2.png',(np.squeeze(preds_test[1])),cmap='gray')\n",
    "plt.imsave('img3.png',(np.squeeze(preds_test[2])),cmap='gray')\n",
    "plt.imsave('img4.png',(np.squeeze(preds_test[3])),cmap='gray')\n",
    "plt.imsave('img5.png',(np.squeeze(preds_test[4])),cmap='gray')\n",
    "plt.imsave('img6.png',(np.squeeze(preds_test[5])),cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c865f0fsis3k"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "test_files=[]\n",
    "TEST_PATH=\"/content/files512/testdata/\"\n",
    "for file in os.listdir(\"/content/files512/testdata/\"):\n",
    "    if file.endswith(\".png\"):\n",
    "        test_files.append(file)\n",
    "X_test = np.zeros((len(test_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for file in test_files:\n",
    "    path = TEST_PATH + file\n",
    "    img = cv2.imread(path)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #img = np.expand_dims(img,axis=2)\n",
    "    X_test[i] = img\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HopSCZHfCy8m"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "X_test = np.zeros((len(test_files), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "for file in test_files:\n",
    "    path = TEST_PATH + file\n",
    "    img = cv2.imread(path)[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "    #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    #img = np.expand_dims(img,axis=2)\n",
    "    X_test[i] = img\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ilq2VKHcC8dS",
    "outputId": "d609d775-75f6-4e4b-9395-72435a33bb8c"
   },
   "outputs": [],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_y7UcLiVF94",
    "outputId": "759fbb49-5efa-483c-9e86-5db89fbd2242"
   },
   "outputs": [],
   "source": [
    "preds_test = model2.predict(X_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHhGUy_RVKLd"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds_test_t= (preds_test>0.1).astype(np.uint8)\n",
    "plt.imsave('img1.png',(np.squeeze(preds_test_t[0])),cmap='gray')\n",
    "plt.imsave('img2.png',(np.squeeze(preds_test_t[1])),cmap='gray')\n",
    "plt.imsave('img3.png',(np.squeeze(preds_test_t[2])),cmap='gray')\n",
    "plt.imsave('img4.png',(np.squeeze(preds_test_t[3])),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtjDW8f9VPvG",
    "outputId": "cb88156d-1fd8-46ee-d2d8-bf5aa63058c9"
   },
   "outputs": [],
   "source": [
    "!zip -r model.zip /content/trained_model_512/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_pR-u_aZP6U"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.layers import Input, Conv2D, Reshape\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCWnkDJnXBdE"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return numerator / (denominator + tf.keras.backend.epsilon()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLU-DsyiZ5FL"
   },
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6omM0hH8YLBk"
   },
   "outputs": [],
   "source": [
    "\n",
    "model3 = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model3.compile(optimizer='sgd', loss=loss, metrics=[dice_coefficient])\n",
    "model3.optimizer.lr=0.0001\n",
    "\n",
    "\n",
    "#model.save('trained_model.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 774
    },
    "id": "TZiwW-kdYcy5",
    "outputId": "365a2811-2212-47f2-c247-4e6ef6447cd3"
   },
   "outputs": [],
   "source": [
    "\n",
    "model3.fit(X_train,Y_train,batch_size=32,epochs=30,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Fecw5OlY9L0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of 1024_morelayers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
